{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886d32f-24b8-431b-b2d9-cdf709bf8768",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from notebookutils import mssparkutils\n",
    "from pyspark.sql.functions import udf, col, from_json, concat_ws, explode, current_timestamp\n",
    "from pyspark.sql.types import StringType, Row, StructType, StructField, ArrayType, MapType\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "\n",
    "from synapse.ml.services import AnalyzeDocument\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "from synapse.ml.services.openai import OpenAIChatCompletion\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e13306-cbe0-4658-89b3-68cc40f466b8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ff2d9-67a9-4e3f-a658-0e4844c06567",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Getting all necessary secrets \n",
    "\n",
    "ai_services_key = mssparkutils.credentials.getSecret('https://keyvaultnew.vault.azure.net/', 'DocIntelligenceKey')\n",
    "ai_services_location = mssparkutils.credentials.getSecret('https://keyvaultnew.vault.azure.net/', 'DocIntelligenceRegion') \n",
    "ai_aoai_key = mssparkutils.credentials.getSecret('https://keyvaultnew.vault.azure.net/', 'AOAIKey')\n",
    "ai_aoai_url = mssparkutils.credentials.getSecret('https://keyvaultnew.vault.azure.net/', 'AOAIURL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9ca04-7129-46e1-8a9c-4739513ff9ae",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Input parameter\n",
    "document_path = \"Files/PDF/MYPDFFILE.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09006831-9147-46e8-9687-6d216d95a26e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"binaryFile\")\n",
    "    .load(document_path)\n",
    "    .limit(10)\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbfba8-a79a-4483-a1a2-8c91c79d2d98",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "analyze_document = (\n",
    "    AnalyzeDocument()\n",
    "    .setPrebuiltModelId(\"prebuilt-layout\")\n",
    "    .setSubscriptionKey(ai_services_key)\n",
    "    .setLocation(ai_services_location)\n",
    "    .setImageBytesCol(\"content\")\n",
    "    .setOutputCol(\"result\")\n",
    "    .setPages(\"1-5\") # for sake of quick processing, only read the first 15 pages of the documents\n",
    ")\n",
    "\n",
    "analyzed_df = (\n",
    "    analyze_document.transform(df)\n",
    "    .withColumn(\"output_content\", col(\"result.analyzeResult.content\"))\n",
    "    .withColumn(\"paragraphs\", col(\"result.analyzeResult.paragraphs\"))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d5041-903e-4c8f-bd38-e35aac79abab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "analyzed_df = analyzed_df.drop(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65f967-3afd-456d-8315-a3a5269260ac",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define the JSON structure you want to extract\n",
    "json_structure = {\n",
    "  \"myjsonstructure\": {\n",
    "    \"id\": \"\",\n",
    "    \"date\": \"\",\n",
    "    \"attribute 1\": \"\",\n",
    "    \"attribute 2\": \"\",\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db513f4b-fb4a-4ad1-b6aa-d2736004f715",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def make_message(role, content):\n",
    "    return Row(role=role, content=content, name=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40f8f1-b51e-446c-a58b-5d90a35e0f6d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for i in analyzed_df.collect(): \n",
    "    messages.append(\n",
    "        [\n",
    "            (\n",
    "                [\n",
    "                    make_message(\n",
    "                        \"system\", \"You are a useful assistant supporting with structured extraction of information from texts. Don't add any comments or explaining text. Always only return the expected JSON filled with the content that was asked for. When you are asked to extract a Project Reference number search for a string that is between six and 15 characters long and can contain characters and numbers like 'MGR65002', 'PCM031', 'MDRCOVID19', 'M819943'. When an Audittype is asked this can be one of 'ISRS', 'ISA'\"\n",
    "                    ),\n",
    "                    make_message(\"user\", f\"Extract the following information in JSON format: {json.dumps(json_structure)} from the following text: {i['output_content']}\"),\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f3c44-3759-456b-911a-8498b00fd9a5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "colname = [\"messages\"]\n",
    "chat_df = spark.createDataFrame(messages, colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170275cb-40f0-4fe4-83f1-de1edb0b5df7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Using a provisioned AOAI gpt-4-32k model in case Fabric Copilot is not available\n",
    "\n",
    "response = (\n",
    "    OpenAIChatCompletion()\n",
    "    .setSubscriptionKey(ai_aoai_key)\n",
    "    .setDeploymentName(\"gpt-4-32k\")\n",
    "    .setUrl(ai_aoai_url)\n",
    "    .setMessagesCol(\"messages\")\n",
    "    .setErrorCol(\"error\")\n",
    "    .setOutputCol(\"chat_completions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c438b4d-d36b-400e-a72a-86fe2011ccfb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Using the Fabric built-in AOAI model in case Fabric Copilot is available = no explicit AOAI Model necessary\n",
    "'''\n",
    "response =(\n",
    "    OpenAIChatCompletion()\n",
    "    .setDeploymentName(\"gpt-4-32k\")\n",
    "    .setMessagesCol(\"messages\")\n",
    "    .setErrorCol(\"error\")\n",
    "    .setOutputCol(\"chat_completions\")\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224bc39-8d26-4276-a237-7815dc600354",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "intermediate_df = response.transform(chat_df).select(\"messages\", \"chat_completions.choices.message.content\")\n",
    "intermediate_df = intermediate_df.withColumn(\"content_str\", concat_ws(\"\", col(\"content\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0079c-d0e3-4a35-98b5-971ce0932cda",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "myjson_schema = ArrayType(StructType([\n",
    "    StructField(\"myjsonstructure\", StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"attribute 1\", StringType(), True),\n",
    "        StructField(\"attribute 2\", StringType(), True),\n",
    "        ...\n",
    "])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014f60c-ad02-4995-b5e4-b4fddb766778",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "new_df = intermediate_df.withColumn(\"parsedContent\", from_json(col(\"content_str\"), myjson_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a01493-79be-4574-9aa1-2b9a07c5281e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "new_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a76895-28f6-49f5-b550-d12aa2a3552a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "new_df_exploded = new_df.select(explode(\"parsedContent\").alias(\"parsedContent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094281ed-d73d-41fb-91d2-e1477cbebcfe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "new_dfs_info = [\n",
    "    {\"newDataFrameName\": \"df_myjsonstructure\", \"columnNames\": [\"parsedContent.root.id\", \"parsedContent.root.attribute 1\", \"parsedContent.root.attribute 2\", \"...\", current_timestamp().alias(\"insert_datetime\")]},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c66dc-8a4f-41b2-840a-923aa0b97711",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def create_new_dataframes(sourceDataFrame, newDataFrames):\n",
    "    \n",
    "    # Dictionary to store the new DataFrames\n",
    "    new_dfs = {}\n",
    "    \n",
    "    # Iterate through the array of newDataFrames\n",
    "    for row in newDataFrames:\n",
    "        new_df_name = row[\"newDataFrameName\"]\n",
    "        column_names = row[\"columnNames\"]\n",
    "        print(column_names)\n",
    "        # Select the specified columns from the source DataFrame\n",
    "        new_df = sourceDataFrame.select(*column_names)\n",
    "        \n",
    "        # Store the new DataFrame in the dictionary\n",
    "        new_dfs[new_df_name] = new_df\n",
    "    \n",
    "    return new_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edae70-b2ca-4795-a861-809e6cc890da",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "new_dfs = create_new_dataframes(new_df_exploded, new_dfs_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9221a18-ab7f-438a-9db3-e52b1ad19660",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "output_path = 'Tables/'\n",
    "\n",
    "for df_name, df in new_dfs.items():\n",
    "        # Write each DataFrame as a Delta Lake table\n",
    "        df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .option(\"mergeSchema\", \"true\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save(f\"{output_path}/{df_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "eb86c034-37eb-4552-924c-e03162873831",
    "default_lakehouse_name": "patsLakehouse2",
    "default_lakehouse_workspace_id": "aae94c66-eabb-4628-a4d4-c3b3565ce9a4",
    "known_lakehouses": [
     {
      "id": "912762ce-1c78-476b-b8ca-028fdf739a94"
     },
     {
      "id": "eb86c034-37eb-4552-924c-e03162873831"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    },
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
